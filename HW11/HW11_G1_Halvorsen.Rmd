---
title: "HW11 Group 1, Austin Halvorsen"
author: "Pedram Jahangiry"
date: "Dec 1 2020"
output:
  word_document: 
    keep_md: yes
  pdf_document: default
---

\newpage

# Problems

```{r message=FALSE, warning=FALSE, include=FALSE}
# setup
library(tidyverse)
library(stargazer)
library(wooldridge)
library(pander)
library(car)
```

## Question 1

### (i)

Because this is a log-linear model, we interpret the coefficient on *cigs* as an increase of 10 more cigarettes a day results in a 4.4% lower birthrate.

### (ii)

Holding all other factors constant, our model suggests that white children weigh 5.5% more than a non-white child.

To calculate if this is significant or not, we need to calculate the t-stat, under the hypothesis, $H_0: \mu_m=0$ and $H_1: \mu_m\neq0$. We get a t value of $t=\frac{0.055-0}{0.013}=4.23$. This is significant at the 1% level, so we can say that the difference between white and non white babies is statistically significant.

### (iii)

Looking at motheduc, if a mother has an additional year of education, then the estimated birth weight of the is approximately 0.3% higher.

To see if this is significant, we find the t value: $t=\frac{0.003-0}{0.003}=1$ This is insignificant at the 1% level so we shouldn't investigate this relationship.

### (iv)

In order to compute the F-statistic, we would need to reestimate the first equation with the same amount of observations as the second equation.

\newpage

## Question 2

### (i)

Looking at our t-stat, we get $t=\frac{2.19}{0.53}=4.132$, which means that this is significant at our 1% level and it should remain in our model.

Finding the optimum size, we need to look at the partial derivative. So where:

$$
\begin{aligned}
\frac{\delta sat}{\delta hsize}=19.30-2.19hsize^2=0 \\
hsize=\frac{19.30}{4.38} \\
hsize = 4.41
\end{aligned}
$$
Since this is measured in hundreds and based on our estimated model, we get 4.41 * 100 = 441 is the optimal high school size.

### (ii)

Holding *hsize* fixed, the estimated difference in SAT scores between nonblack females and nonblack males is 45 points lower. 
To see if this is significant, we calculate the t statistic $t=\frac{-45.09-0}{4.29}=-10.51$, which shows us that this is significant at the 1% level.

### (iii)

The estimated difference in SAT score between nonblack males and black males is about 170 points.
$t=\frac{-169.81-0}{12.71}=-13$

This is significant at the 1% level. 

### (iv)

The estimated score between black females and nonblack females is the difference where our interaction term black and female equal 1 and and black equals 1. This gives us a difference of $-169.81+62.31=-107.5$c

\newpage

## Question 3

### (i)

Given that $inlf=1-outlf$, then $outlf=1-inlf$ and $inlf=\beta_0+\beta_1nwifeinc+\beta_2educ+\beta_3exper...$ 
Therefore, 

$$
\begin{aligned}
outlf=1-(\beta_0+\beta_1nwifeinc+\beta_2educ+\beta_3exper...) \\ 
=(1-\beta_0)-(\beta_1nwifeinc+\beta_2educ+\beta_3exper...) \\ 
=(1-\beta_0)-\beta_1nwifeinc-\beta_2educ-\beta_3exper...)
\end{aligned}
$$
We can see here now that our intercept becomes $1-\beta_0$ and our slope estimates will change from positive to negative.

### (ii)

The standard error will stay the same, since the spread is not influenced by the sign of the coefficients.

### (iii)

The $R^2$ value will remain unchanged, since we are using the same set of independent variables.

\newpage

# Computer Exercises

## Question 4

### (i)
```{r comment=NA}
df2 <- gpa1
mrm4 <- lm(colGPA~PC+hsGPA+ACT+mothcoll+fathcoll, df2)
stargazer(mrm4, type="text")
```



When adding in *mothcoll* and *fathcoll*, the effect of PC changes from 0.157 to 0.152. The P-value for PC is still less than 0.05, so it is statistically significant.

### (ii)

```{r}
pander(linearHypothesis(mrm4, c("mothcoll", "fathcoll")))
```

The p-value of the F-stat is 0.7834 which is higher than our 5% significance level indicating that they are jointly insignificant at the 5% level.

### (iii)
```{r}
mrm4a <- lm(colGPA~PC+hsGPA+I(hsGPA^2)+ACT+mothcoll+fathcoll, df2)
stargazer(mrm4,mrm4a, type='text')
summary(mrm4a)
```

The P-value for $hsGPA^2$ 0.115 which is greater than the critical p-value of 0.05, so we probably do not need to add $hsGPA^2$ in not needed.

\newpage

## Question 5

### (i)

```{r comment=NA}
df <- wage2
mrm1 <- lm(lwage~educ+exper+tenure+married+black+south+urban, df)
pander(summary(mrm1),add.significance.stars = T)
```
 
Our estimated model is: 
$$
\begin{gather}
\hat{log(wage)}=5.395+0.06543educ+0.01404exper+0.01175tenure+0.1994married \\ -0.1883black-0.0909south+0.1839urban \\ \\
n=935 \text{ }R^2=0.253\text{ Adjusted } \bar{R^2}=0.2469 
\end{gather}
$$
Our coefficient on *black*, holding all else constant would indicate that the monthly salary of blacks is 18.83% less than nonblacks. The p-value is very low (.000000068397), which would tell us that this is significant at the 5% level, or that the difference between salaries in black and nonblack is statistically significant.

### (ii)

```{r warning=FALSE, comment=NA}
df$expersq = df$exper^2
df$tenuresq = df$tenure^2
mrm2 <- lm(lwage~educ+exper+tenure+married+black+south+urban+expersq+tenuresq, df)
stargazer(mrm1, mrm2, type='text')
pander(summary(mrm2))
```

```{r}
pander(linearHypothesis(mrm2, c("expersq","tenuresq"))) 
```

With an F stat of 0.226, this is greater than .20 for a 20% significance level. This would mean that $tenure^2$ and $exper^2$ are jointly insignificant at the 20% level.

### (iii)

```{r comment=NA}
mrm2b <- lm(lwage~educ+exper+tenure+married+black+south+urban+I(educ*black), df)
pander(summary(mrm2b))
```

The p-value for $educ*black$ is 0.2626 which is greater than our level of significance, meaning that return to education does not depend on race at the 5% level.

### (iv)
```{r comment=NA}
mrm2c <- lm(lwage~educ+exper+tenure+married+black+south+urban+I(married*black), df)
pander(summary(mrm2c))
```

If you are married a non-black, you are earning 17.9467% more than married black. 

\newpage

## Question 6

```{r comment=NA, include=FALSE}
df1 <- apple
```

### (i)

```{r comment=NA}
df_dummy <- df1 %>% 
  mutate(ecobuy = case_when(
    ecolbs == 0 ~ 0,
    TRUE ~ 1))

pander(prop.table(table(df_dummy$ecobuy)))
```

From our data, a reported 62.42% of families say that they buy ecolabeled apples.

### (ii)

```{r}
mrm2 <- lm(ecobuy~ecoprc+regprc+faminc+hhsize+educ+age, df_dummy)
pander(summary(mrm2))
```

Our estimated model is: 

$$
\begin{gather}
\hat{ecobuy}=0.4237-0.8026ecoprc+0.7193regprc+0.0005518faminc+ \\ 0.02382hhsize+0.02478educ-0.0005008age \\ \\
\text{Where }n=660 \text{, } R^2=0.1098 \text{ and Adjusted }\bar{R^2}=0.1016 
\end{gather}
$$
 
### (iii)
```{r comment=NA}
summary(mrm2)$fstatistic
pander(linearHypothesis(mrm2, c("faminc","hhsize","educ", "age")))
```

With a p-value of 0.0015, we can conclude that the non-price factors are statistically significant at the 5% level.
The highest influential factor besides price that effects the decision to buy eco-apples is $educ$.
This makes sense because the more education you have, the more likely you are to understand the benefits of these types of apples and thus increase the demand.

### (iv)
```{r comment=NA}
mrm3 <- lm(ecobuy~ecoprc+regprc+I(log(faminc))+hhsize+educ+age, df_dummy)
stargazer(mrm2,mrm3, type='text')
```

Looking at our output, our adjusted $R^2$ is slightly better than our normal $R^2$, so we should use the $log(faminc)$ variable to have the model fit the data better.

### (v)
```{r comment=NA}
pander(summary(mrm3))
```

None of the estimated probabilities are negative, however two are above 1. This is strange because we shouldn't have predicted probilities that are more than 1. 

### (vi)
```{r}
df_dummy %>%
  group_by(ecobuy) %>% 
  summarise(n = n())

ecofam <- tibble(predict(mrm3))
ecofam %>% 
  rename(prediction = 'predict(mrm3)') %>% 
  mutate(model.predict = case_when( 
    prediction <= 0.5 ~ 0,
    TRUE ~ 1
  )) %>%
  group_by(model.predict) %>% 
  summarise(n = n())
```

Based on our predictions, the estimated number of 1's is 486, but the actual is 412. This would be 118%, which seems high.
For 0's, the predicted was 174 with an actual of 248. The percentage predicted correctly was 70%.
The model where ecobuy was 1 was still best predicted by the model.